{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e40935dd",
   "metadata": {},
   "source": [
    "## Homework 4: Decision Trees\n",
    "### Distinguishing Rock, Pop, Hip-Hop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e189b07c",
   "metadata": {},
   "source": [
    "    Question1\n",
    "        Implement a function called dtree which takes the following parameters:\n",
    "            • train\n",
    "            • criterion:(gini or entropy)\n",
    "            • max_depth\n",
    "            • min_instances=2\n",
    "            • target_impurity=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5c803819",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter \n",
    "from math import log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "41f48fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading csv files into training and testing variables\n",
    "testing = pd.read_csv('spotify_test.csv')\n",
    "training = pd.read_csv('spotify_train.csv')\n",
    "\n",
    "COL_TRACK_GENRE = \"track_genre\"\n",
    "# drop duplicates from both datasets\n",
    "training.drop_duplicates(keep=False, inplace=True, subset=testing.columns.difference([COL_TRACK_GENRE]))\n",
    "testing.drop_duplicates(keep=False, inplace=True, subset=testing.columns.difference([COL_TRACK_GENRE]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9abb886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Count\n",
    "def total(cnt):\n",
    "    return sum(cnt.values())\n",
    "\n",
    "#Gini Method\n",
    "#Gini impurity measures the frequency at which any element of the dataset \n",
    "#will be mislabelled when it is randomly labeled.\n",
    "def gini(cnt):\n",
    "    tot = total(cnt)\n",
    "    return 1 - sum([(v/tot)**2 for v in cnt.values()])\n",
    "\n",
    "#Entropy Method\n",
    "#Entropy is a measure of information that indicates the disorder of the features with the target. \n",
    "#Similar to the Gini Index, the optimum split is chosen by the feature with less entropy.\n",
    "def entropy(cnt):\n",
    "    tot = total(cnt)\n",
    "    return sum([(-v/tot) * log2(v/tot) for v in cnt.values()])\n",
    "    \n",
    "def wavg(cnt1, cnt2, measure):\n",
    "    tot1 = total(cnt1)\n",
    "    tot2 = total(cnt2)\n",
    "    tot = tot1 + tot2\n",
    "    return (measure(cnt1) * tot1 + measure(cnt2) * tot2) / tot\n",
    "\n",
    "def evaluate_split(df, class_col, split_col, feature_val, measure):\n",
    "    df1, df2 = df[df[split_col] <= feature_val], df[df[split_col] > feature_val]\n",
    "    cnt1, cnt2 = Counter(df1[class_col]), Counter(df2[class_col])\n",
    "    return wavg(cnt1, cnt2, measure)\n",
    "\n",
    "def best_split_for_column(df, class_col, split_col, method):\n",
    "    best_v = ''\n",
    "    best_meas = float(\"inf\")\n",
    "    \n",
    "    for v in set(df[split_col]):\n",
    "        \n",
    "        meas = evaluate_split(df, class_col, split_col, v, method)\n",
    "        if  meas < best_meas:\n",
    "            best_v = v\n",
    "            best_meas = meas\n",
    "    \n",
    "    return best_v, best_meas\n",
    "\n",
    "def best_split(df, class_col, method):\n",
    "    best_col = 0\n",
    "    best_v = ''\n",
    "    best_meas = float(\"inf\")\n",
    "    \n",
    "    for split_col in df.columns:\n",
    "        if split_col != class_col:\n",
    "            v, meas = best_split_for_column(df, class_col, split_col, method)\n",
    "            if meas < best_meas:\n",
    "                best_v = v\n",
    "                best_meas = meas\n",
    "                best_col = split_col\n",
    "                \n",
    "    return best_col, best_v, best_meas\n",
    "\n",
    "#Function of dtree taking following parameters\n",
    "def dtree(train, criterion, max_depth=None, min_instances=2, target_impurity=0.0, depth=0):\n",
    "    num_instances = len(train)\n",
    "    num_classes = len(train[train.columns[-1]].unique())\n",
    "    class_counts = train[train.columns[-1]].value_counts()\n",
    "\n",
    "    #Checking max_depth and min_depth \n",
    "    if num_classes == 1 or (max_depth is not None and depth == max_depth) or num_instances < min_instances:\n",
    "        return None, None, num_instances, class_counts.idxmax(), 0, depth, None, None\n",
    "    \n",
    "    best_col, best_v, best_meas = best_split(train, train.columns[-1], criterion)\n",
    "\n",
    "    left_split = train[train[best_col] <= best_v]\n",
    "    right_split = train[train[best_col] > best_v]\n",
    "\n",
    "    if left_split.empty or right_split.empty:\n",
    "        left_split = train[train[best_col] == best_v]\n",
    "        right_split = train[train[best_col] != best_v]\n",
    "\n",
    "    #Checking for target impurity\n",
    "    if best_meas <= target_impurity:\n",
    "        left = None, None, len(left_split), left_split[train.columns[-1]].value_counts().idxmax(), 0, depth + 1, None, None\n",
    "        right = None, None, len(right_split), right_split[train.columns[-1]].value_counts().idxmax(), 0, depth + 1, None, None\n",
    "        return best_col, best_v, num_instances, class_counts.idxmax(), best_meas, depth, left, right\n",
    "\n",
    "    #Recursing\n",
    "    left = dtree(left_split, criterion, max_depth, min_instances, target_impurity, depth + 1)\n",
    "    right = dtree(right_split, criterion, max_depth, min_instances, target_impurity, depth + 1)\n",
    "    \n",
    "    return best_col, best_v, num_instances, class_counts.idxmax(), best_meas, depth, left, right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d0832e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate predictions. Get a list of predictions for each row in data\n",
    "def predict(model, data):\n",
    "    predictions = []\n",
    "    for i in range(len(data)):\n",
    "        predictions.append(predict_row(model, data.iloc[i]))\n",
    "    return predictions\n",
    "\n",
    "# Function to generate predictions for a row\n",
    "def predict_row(model, row):\n",
    "    node = model\n",
    "    majority_class = node[3]\n",
    "    left = node[6]\n",
    "    right = node[7]\n",
    "\n",
    "    if node[0] is None:\n",
    "        return majority_class\n",
    "    else:\n",
    "        if row[node[0]] <= node[1]:\n",
    "            return predict_row(left, row)\n",
    "        else:\n",
    "            return predict_row(right, row)\n",
    "\n",
    "#cross validation to determine overall validation error\n",
    "#Returning avg. accuracies\n",
    "def cross_validate(train, criterion, max_depth=None, min_instances=2, target_impurity=0.0, k=10):\n",
    "    fold_size = int(len(train) / k)\n",
    "    accuracies = []\n",
    "    for i in range(k):\n",
    "        training_fold = pd.concat([train.iloc[:i * fold_size], train.iloc[(i + 1) * fold_size:]]).reset_index(drop=True)\n",
    "        validation_fold = train.iloc[i * fold_size:(i + 1) * fold_size].reset_index(drop=True)\n",
    "\n",
    "        model = dtree(training_fold, criterion, max_depth, min_instances, target_impurity)\n",
    "        predictions = predict(model, validation_fold)\n",
    "        labels = validation_fold.track_genre\n",
    "\n",
    "        accuracy = np.sum(predictions == labels) / len(labels)\n",
    "        accuracies.append(accuracy)\n",
    "    return np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e7aa9e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter tuning which searches for possible combinations that produces the best validation accuracy.\n",
    "def hyperparameter_tuning(train):\n",
    "    best_params = None\n",
    "    best_accuracy = 0\n",
    "    #FEATURE SELECTION AND SPLITTING CRITERION\n",
    "    criterions = [gini, entropy]\n",
    "    max_depths = np.arange(0, 20, 1)\n",
    "    min_instances = np.arange(2, 20, 1)\n",
    "    target_impurities = np.arange(0.0, 0.5, 0.1)\n",
    "    \n",
    "    #STOPPING CRITERIAS\n",
    "    for c in criterions:\n",
    "        for md in max_depths:\n",
    "            for mi in min_instances:\n",
    "                for ti in target_impurities:\n",
    "                    accuracy = cross_validate(train, c, md, mi, ti, 10)\n",
    "\n",
    "                    if accuracy > best_accuracy:\n",
    "                        best_accuracy = accuracy\n",
    "                        best_params = c, md, mi, ti\n",
    "    return best_params, best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters, best_accuracy = hyperparameter_tuning(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c8c25081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<function gini at 0x00000170B96859D0>, 14, 4, 0.1]\n",
      "0.7385679514358962\n"
     ]
    }
   ],
   "source": [
    "# computer blue screened, so I had to hard code our best parameters and accuracy.\n",
    "best_parameters = [gini, 14, 4, 0.1]\n",
    "best_accuracy = 0.7385679514358962\n",
    "print(best_parameters)\n",
    "print(best_accuracy)\n",
    "\n",
    "c = best_parameters[0]\n",
    "md = best_parameters[1]\n",
    "mi = best_parameters[2]\n",
    "ti = best_parameters[3]\n",
    "\n",
    "clf = dtree(training, c, md, mi, ti)\n",
    "\n",
    "predictions = predict(clf, testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7021546261089987\n"
     ]
    }
   ],
   "source": [
    "y_test = testing.track_genre\n",
    "\n",
    "print(\"Accuracy: \", np.sum(predictions == y_test) / len(predictions))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

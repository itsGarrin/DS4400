{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16a17672",
   "metadata": {},
   "source": [
    "### Lab 08: The Confusion Matrix\n",
    "\n",
    "By definition a confusion matrix is such that \n",
    "$C_{i,j}$ is equal to the number of observations known to be in group $i$ and predicted to be in group $j$. Thus in binary classification, where 0=negative, and 1=positive, we have:\n",
    "\n",
    "$C_{0,0}$ are the True Negatives (TN)\n",
    "\n",
    "$C_{1,1}$ are the True Positives (TP)\n",
    "\n",
    "$C_{0,1}$ are the False Positives (FP)\n",
    "\n",
    "$C_{1,0}$ are the False Negatives (FN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac6b9c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your own confusion matrix calculation\n",
    "import numpy as np\n",
    "\n",
    "def confusion_matrix(y_true, y_pred):\n",
    "    \"\"\" Generate a confusion matrix.\n",
    "    y = actual outcomes (0, 1, 2, ...)\n",
    "    y_pred = predicted outcomes (0, 1, 2, ...)\n",
    "    return confusion matrix as a numpy array\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find unique identifiers\n",
    "    unique_classes = set(y_true) | set(y_pred)\n",
    "    n_classes = len(unique_classes)\n",
    "    \n",
    "    # Create matrix (all zeros)\n",
    "    matrix = np.zeros(shape=(n_classes, n_classes), dtype=int)\n",
    "    \n",
    "    # Pair up each actual outcome with the corresponding prediction\n",
    "    actual_prediction = list(zip(y_true, y_pred))\n",
    "    \n",
    "    # For each pair, increment the correct position in the matrix\n",
    "    for i,j in actual_prediction:\n",
    "        matrix[i,j] += 1\n",
    "        \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b651378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perfect Accuracy\n",
      "[[6 0]\n",
      " [0 4]]\n",
      "\n",
      "One False Positive\n",
      "[[5 1]\n",
      " [0 4]]\n",
      "\n",
      "And Three False negatives:\n",
      "[[5 1]\n",
      " [3 1]]\n",
      "\n",
      "FOUR CLASSES: \n",
      "[[5 0 1 0]\n",
      " [0 1 1 2]\n",
      " [0 0 5 0]\n",
      " [1 1 2 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5789473684210527"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perfect prediction\n",
    "y_true = [0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
    "y_pred = [0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
    "print(\"\\nPerfect Accuracy\")\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "# Note we are sticking to the scikit convention that ROWS=ACTUAL, COLUMNS=PREDICTIONS\n",
    "# Let's introduce a single false positive (One healthy patient predicted to be sick.)\n",
    "y_true = [0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
    "y_pred = [0, 0, 1, 0, 0, 0, 1, 1, 1, 1]\n",
    "print(\"\\nOne False Positive\")\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "# And 3/4 of our sick patients are mistakenly treated as healthy!\n",
    "y_true = [0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
    "y_pred = [0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
    "print(\"\\nAnd Three False negatives:\")\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "# It works for multiple class labels too\n",
    "# but now True/False Positives/Negatives doesn't apply\n",
    "\n",
    "print(\"\\nFOUR CLASSES: \")\n",
    "y_true = [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3]\n",
    "y_pred = [0, 0, 2, 0, 0, 0, 1, 3, 3, 2, 2, 2, 2, 2, 2, 1, 2, 2, 0]\n",
    "C = confusion_matrix(y_true, y_pred)\n",
    "print(C)\n",
    "C.diagonal().sum() / C.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd4a856f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_true, y_pred, places=4):\n",
    "    \"\"\" Generate accuracy scores for classifier.\n",
    "    Round each score to <places> decimal places \"\"\"\n",
    "    \n",
    "    scores = {}\n",
    "    C = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    \n",
    "    scores['accuracy'] = C.diagonal().sum() / C.sum()\n",
    "    \n",
    "    # Implement scores for binary classification\n",
    "    # Here is a start....\n",
    "    \n",
    "    if C.shape == (2,2):\n",
    "        TN, FP, FN, TP = C.ravel() #  ravel flattens the array row by row\n",
    "        scores['sensitivity'] = TP / (TP + FN)\n",
    "    else:\n",
    "        pass # do later\n",
    "        \n",
    "    return scores  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1d3eb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.5714285714285714, 'sensitivity': 0.3333333333333333}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [0,0,0,0,1,1,1]\n",
    "y_pred = [1,0,0,0,0,0,1]\n",
    "\n",
    "scores = metrics(y_true, y_pred)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f56d78b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>147.042500</td>\n",
       "      <td>23.264000</td>\n",
       "      <td>30.554000</td>\n",
       "      <td>14.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>85.854236</td>\n",
       "      <td>14.846809</td>\n",
       "      <td>21.778621</td>\n",
       "      <td>5.217457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.375000</td>\n",
       "      <td>9.975000</td>\n",
       "      <td>12.750000</td>\n",
       "      <td>10.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>149.750000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>12.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>218.825000</td>\n",
       "      <td>36.525000</td>\n",
       "      <td>45.100000</td>\n",
       "      <td>17.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>296.400000</td>\n",
       "      <td>49.600000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TV       radio   newspaper       sales\n",
       "count  200.000000  200.000000  200.000000  200.000000\n",
       "mean   147.042500   23.264000   30.554000   14.022500\n",
       "std     85.854236   14.846809   21.778621    5.217457\n",
       "min      0.700000    0.000000    0.300000    1.600000\n",
       "25%     74.375000    9.975000   12.750000   10.375000\n",
       "50%    149.750000   22.900000   25.750000   12.900000\n",
       "75%    218.825000   36.525000   45.100000   17.400000\n",
       "max    296.400000   49.600000  114.000000   27.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the advertising dataset and describe\n",
    "\n",
    "import pandas as pd\n",
    "adv = pd.read_csv('Advertising.csv')\n",
    "adv = adv.iloc[:, 1:]\n",
    "adv.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cdb6900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a cutoff for HIGH sales\n",
    "adv.sales = (adv.sales>=14).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acd7c319",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model as lm\n",
    "\n",
    "def perceptron_scikit(data):\n",
    "    \"\"\" Run the scikit-learn Perceptron model on the data \"\"\"\n",
    "\n",
    "    X = data[data.columns[:-1]]\n",
    "    y = data.iloc[:, -1]\n",
    "    clf = lm.Perceptron()\n",
    "    clf.fit(X,y)\n",
    "    w = list(clf.intercept_) + list(clf.coef_[0])\n",
    "    return w, clf.predict(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25e01260",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, sales_pred = perceptron_scikit(adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b67448da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50, 60],\n",
       "       [ 8, 82]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(adv.sales, sales_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a799fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.66, 'sensitivity': 0.9111111111111111}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How does perceptron do on this data?\n",
    "metrics(adv.sales, sales_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c195de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.55, 'sensitivity': 0.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What if we always predict LOW sales?\n",
    "# Accuracy drops to the frequency of low sales and sensitivity is 0%\n",
    "\n",
    "metrics(adv.sales, [0]*len(adv.sales))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66785f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.45, 'sensitivity': 1.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What if we always predict HIGH sales?\n",
    "# Accuracy drops to the frequency of high sales and sensitivity is 100%!\n",
    "\n",
    "metrics(adv.sales, [1]*len(adv.sales))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f65e433",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b55a753",
   "metadata": {},
   "source": [
    "### Lab 09: Converting word lists to feature vectors\n",
    "DS4400 / Rachlin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aab30d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['be', 'is', 'not', 'or', 'question', 'that', 'the', 'to']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding unique words in text \n",
    "\n",
    "phrase = \"to be or not to be that is the question\"\n",
    "words = phrase.lower().split()\n",
    "unique = sorted(list(set(words)))\n",
    "unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ee2d9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'to': 2,\n",
       " 'be': 2,\n",
       " 'or': 1,\n",
       " 'not': 1,\n",
       " 'that': 1,\n",
       " 'is': 1,\n",
       " 'the': 1,\n",
       " 'question': 1}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting words in text\n",
    "from collections import Counter\n",
    "freq = Counter(words)\n",
    "dict(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22d59fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to', 2), ('be', 2), ('or', 1), ('not', 1)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the four most frequent words and their associated frequency\n",
    "freq.most_common(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34af2006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['be', 'not', 'or', 'to']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract just these words into a sorted list\n",
    "common = sorted([x[0] for x in freq.most_common(4)])\n",
    "common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04bbf612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['be', 'is', 'not', 'or', 'question', 'that', 'the', 'to']\n",
      "[1, 0, 1, 0, 0, 0, 1, 1]\n",
      "['be', 'not', 'or', 'to']\n",
      "[1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# New phrase\n",
    "new_phrase = \"i'm not going to be a dentist i want to be a data scientist and study the sea currents\"\n",
    "new_words = new_phrase.split()\n",
    "# A vectorized phrase\n",
    "# 1 = word appears in our phrase\n",
    "# 0 = word does not appear in our phrase\n",
    "\n",
    "print(unique)\n",
    "print([int(w in new_words) for w in unique])\n",
    "print(common)\n",
    "print([int(w in new_words) for w in common])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4e1c3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['be', 'is', 'not', 'or', 'question', 'that', 'the', 'to']\n",
      "[2, 0, 1, 0, 0, 0, 1, 2]\n",
      "['be', 'not', 'or', 'to']\n",
      "[2, 1, 0, 2]\n"
     ]
    }
   ],
   "source": [
    "# Repeat vectorization, but this time store frequency of word in our phrase\n",
    "# n = word appears in our phrase n times\n",
    "# 0 = word does not appear in our phrase\n",
    "\n",
    "\n",
    "# New phrase\n",
    "new_phrase = \"i'm not going to be a dentist i want to be a data scientist and study the sea currents\"\n",
    "new_words = new_phrase.split()\n",
    "new_count = Counter(new_words)\n",
    "\n",
    "\n",
    "print(unique)\n",
    "print([new_count[w] for w in unique])\n",
    "print(common)\n",
    "print([new_count[w] for w in common])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d80ed40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reusable function\n",
    "from collections import Counter\n",
    "\n",
    "def word_vector(words, word_list, use_frequency=False):\n",
    "    \"\"\" Convert a list of words to a vector by comparing with words in word_list\n",
    "    words: A list of words which we convert to a vector\n",
    "    word_list: The chosen words against which we compare\n",
    "    use_frequency: if False, vector components are 1/0, else n = # of occurrences\n",
    "    \"\"\"\n",
    "    \n",
    "    word_list = sorted(list(set(word_list)))\n",
    "\n",
    "    if use_frequency:    \n",
    "        count = Counter(words)\n",
    "        return [count[w] for w in word_list]\n",
    "    else:\n",
    "        return [int(w in words) for w in word_list]\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3636fc92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 0, 0, 0, 1, 1]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_phrase = \"i'm not going to be a dentist i want to be a data scientist and study the sea currents\"\n",
    "word_vector(new_phrase.split(), unique, use_frequency=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8de6a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
